<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Codex CLI Analysis</title>
    <style>
        :root {
            --primary-color: #4a6cf7;
            --secondary-color: #6c757d;
            --background-color: #f8f9fa;
            --text-color: #212529;
            --light-gray: #e9ecef;
            --white: #ffffff;
            --dark: #343a40;
            --success: #28a745;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
        }
        
        .container {
            max-width: 1140px;
            margin: 0 auto;
            padding: 0 15px;
        }
        
        header {
            background-color: var(--white);
            box-shadow: 0 2px 15px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        
        .header-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 20px 0;
        }
        
        .logo {
            font-size: 24px;
            font-weight: 700;
            color: var(--primary-color);
        }
        
        .hero {
            padding: 80px 0;
            background: linear-gradient(135deg, #4a6cf7 0%, #6a11cb 100%);
            color: var(--white);
            text-align: center;
        }
        
        .hero h1 {
            font-size: 48px;
            margin-bottom: 20px;
            line-height: 1.2;
        }
        
        .hero p {
            font-size: 20px;
            max-width: 800px;
            margin: 0 auto 30px;
        }
        
        .github-button {
            display: inline-block;
            background-color: var(--white);
            color: var(--primary-color);
            padding: 12px 30px;
            border-radius: 30px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s ease;
            margin-top: 20px;
        }
        
        .github-button:hover {
            transform: translateY(-3px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
        }
        
        .main-content {
            padding: 60px 0;
        }
        
        .article {
            background-color: var(--white);
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
            padding: 40px;
            margin-bottom: 30px;
        }
        
        .article h2 {
            color: var(--primary-color);
            margin-bottom: 20px;
            font-size: 32px;
        }
        
        .article h3 {
            margin: 30px 0 15px;
            font-size: 24px;
        }
        
        .article p {
            margin-bottom: 20px;
            font-size: 18px;
        }
        
        .article ul {
            margin-bottom: 20px;
            padding-left: 20px;
        }
        
        .article li {
            margin-bottom: 10px;
            font-size: 18px;
        }
        
        .article code {
            background-color: var(--light-gray);
            padding: 2px 5px;
            border-radius: 4px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 16px;
        }
        
        .code-evidence {
            display: inline-block;
            background-color: #e8f4ff;
            border-left: 3px solid var(--primary-color);
            padding: 3px 8px;
            margin: 0 2px;
            border-radius: 4px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 15px;
            color: #0366d6;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .code-evidence:hover {
            background-color: #d1e6ff;
            text-decoration: underline;
        }
        
        .article img {
            max-width: 100%;
            border-radius: 10px;
            margin: 20px 0;
        }
        
        .video-container {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            height: 0;
            overflow: hidden;
            margin: 30px 0;
            border-radius: 10px;
        }
        
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
        
        .stats-card {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .stat-item {
            flex: 1;
            min-width: 200px;
            background-color: var(--white);
            border-radius: 10px;
            padding: 25px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
        }
        
        .stat-number {
            font-size: 36px;
            font-weight: 700;
            color: var(--primary-color);
            margin-bottom: 10px;
        }
        
        .stat-label {
            font-size: 18px;
            color: var(--secondary-color);
        }
        
        .two-column {
            display: flex;
            gap: 30px;
            margin: 30px 0;
        }
        
        .column {
            flex: 1;
        }
        
        .tech-card {
            background-color: var(--light-gray);
            border-radius: 10px;
            padding: 25px;
            margin-bottom: 20px;
            border-left: 5px solid var(--primary-color);
        }
        
        .tech-card h4 {
            margin-bottom: 15px;
            color: var(--primary-color);
        }
        
        .tech-card p {
            margin-bottom: 0;
        }
        
        .cta-section {
            background-color: var(--dark);
            color: var(--white);
            padding: 80px 0;
            text-align: center;
        }
        
        .cta-section h2 {
            font-size: 36px;
            margin-bottom: 20px;
        }
        
        .cta-section p {
            font-size: 20px;
            max-width: 800px;
            margin: 0 auto 30px;
        }
        
        .cta-button {
            display: inline-block;
            background-color: var(--primary-color);
            color: var(--white);
            padding: 15px 40px;
            border-radius: 30px;
            text-decoration: none;
            font-size: 18px;
            font-weight: 600;
            transition: all 0.3s ease;
        }
        
        .cta-button:hover {
            transform: translateY(-3px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
        }
        
        footer {
            background-color: var(--dark);
            color: var(--white);
            padding: 40px 0;
            text-align: center;
        }
        
        .social-links {
            margin: 20px 0;
        }
        
        .social-links a {
            display: inline-block;
            margin: 0 10px;
            color: var(--white);
            text-decoration: none;
            background-color: rgba(255, 255, 255, 0.1);
            padding: 8px 15px;
            border-radius: 20px;
            transition: all 0.3s ease;
        }
        
        .social-links a:hover {
            background-color: rgba(255, 255, 255, 0.2);
        }
        
        .copyright {
            margin-top: 20px;
            font-size: 14px;
            opacity: 0.7;
        }
        
        pre {
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            margin-bottom: 20px;
            font-family: 'Courier New', Courier, monospace;
            border-left: 4px solid var(--primary-color);
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        
        table, th, td {
            border: 1px solid #ddd;
        }
        
        th, td {
            padding: 12px 15px;
            text-align: left;
        }
        
        th {
            background-color: var(--light-gray);
            font-weight: 600;
        }
        
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        
        .impact-high {
            border-left: 5px solid #dc3545;
            background-color: #fff8f8;
        }
        
        .impact-medium {
            border-left: 5px solid #fd7e14;
            background-color: #fff9f2;
        }
        
        .impact-low {
            border-left: 5px solid #ffc107;
            background-color: #fffcf2;
        }
        
        @media (max-width: 768px) {
            .hero h1 {
                font-size: 36px;
            }
            
            .hero p, .article p, .article li {
                font-size: 16px;
            }
            
            .two-column {
                flex-direction: column;
            }
            
            .stat-item {
                flex: 0 0 100%;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <div class="logo">Codex CLI</div>
                <a href="https://github.com/openai/codex-cli" class="github-button">View on GitHub</a>
            </div>
        </div>
    </header>
    
    <section class="hero">
        <div class="container">
            <h1>OpenAI Codex CLI Analysis</h1>
            <p>A deep dive into the terminal-based AI coding agent that streamlines development workflows</p>
        </div>
    </section>
    
    <div class="main-content">
        <div class="container">
            <div class="stats-card">
                <div class="stat-item">
                    <div class="stat-number">Apache 2.0</div>
                    <div class="stat-label">License</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">Node.js 22+</div>
                    <div class="stat-label">Required Runtime</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">3</div>
                    <div class="stat-label">Platform Support</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">CLI-First</div>
                    <div class="stat-label">Design Philosophy</div>
                </div>
            </div>
            
            <div style="background-color: #f0f7ff; border-radius: 10px; padding: 25px; margin-bottom: 30px; border: 1px solid #d1e6ff;">
                <h3 style="color: #0366d6; margin-bottom: 15px;">📊 Executive Summary</h3>
                <p style="margin-bottom: 15px;">
                    The OpenAI Codex CLI is a terminal-based AI coding assistant that leverages OpenAI's powerful models to help developers generate, modify, and execute code through natural language prompts, all within a terminal environment.
                </p>
                <p>
                    This analysis explores the architecture, security model, and implementation details of the Codex CLI, highlighting both its strengths and limitations for potential enterprise adoption.
                </p>
            </div>
            
            <div class="article">
                <h2>Executive Summary</h2>
                
                <ul>
                    <li><strong>Terminal-Based AI Coding Agent</strong> → Reduces development time and increases productivity for developers who prefer command-line workflows.</li>
                    <li><strong>Secure Sandboxed Execution</strong> → Mitigates security risks through platform-specific sandboxing (Apple Seatbelt on macOS, Docker containers on Linux), enabling safer AI-driven code execution.</li>
                    <li><strong>Flexible Approval Modes</strong> → Allows organizations to balance automation and control, reducing friction while maintaining security guardrails.</li>
                    <li><strong>OpenAI API Integration</strong> → Leverages state-of-the-art LLM capabilities but requires API keys and potential usage costs for teams.</li>
                    <li><strong>Apache 2.0 License</strong> → Enables commercial use and modification with minimal restrictions, reducing legal barriers to adoption.</li>
                </ul>
                
                <h2>Primary Use Case</h2>
                
                <p>The primary use case is enabling developers to generate, modify, and execute code through natural language prompts in a terminal environment (<span class="code-evidence">src/cli.tsx:52-89</span>). This matters commercially because it streamlines development workflows by allowing developers to stay within their terminal environment while leveraging AI capabilities, reducing context switching and accelerating common coding tasks like refactoring, testing, and debugging.</p>
                
                <h2>Workflow Analysis</h2>
                
                <h3>Inputs → Outputs</h3>
                <table>
                    <tr>
                        <th>Inputs</th>
                        <th>Outputs</th>
                    </tr>
                    <tr>
                        <td>Natural language prompts (<span class="code-evidence">cli.tsx:52</span>)</td>
                        <td>Code generation/modifications</td>
                    </tr>
                    <tr>
                        <td>Optional image files (<span class="code-evidence">cli.tsx:58</span>)</td>
                        <td>Terminal output/feedback</td>
                    </tr>
                    <tr>
                        <td>Project context (auto-loaded)</td>
                        <td>File system changes</td>
                    </tr>
                    <tr>
                        <td>Configuration settings (<span class="code-evidence">config.ts</span>)</td>
                        <td>Executed commands (sandboxed)</td>
                    </tr>
                </table>
                
                <h3>Step-by-step Sequence</h3>
                <ol>
                    <li><strong>Initialization</strong>: Parse CLI arguments and load configuration (<span class="code-evidence">cli.tsx:49-172</span>)</li>
                    <li><strong>Context Collection</strong>: Load project files and user instructions (<span class="code-evidence">utils/config.ts</span>)</li>
                    <li><strong>Prompt Processing</strong>: Send user prompt to OpenAI API (<span class="code-evidence">agent/agent-loop.ts</span>)
                        <ul>
                            <li>As a CLI Coding Copilot, Codex doesn't modify user prompts or implement input safeguards</li>
                            <li>Security is instead handled downstream through permission controls and sandboxed execution (see code examples below)</li>
                        </ul>
                    </li>
                    <li><strong>Command Execution</strong>: Run commands in sandbox if approved (<span class="code-evidence">agent/handle-exec-command.ts</span>)</li>
                    <li><strong>File Modification</strong>: Apply patches to files if approved (<span class="code-evidence">agent/apply-patch.ts</span>)</li>
                    <li><strong>Error Handling</strong>: Retry on rate limits, handle timeouts (<span class="code-evidence">agent-loop.ts:25-28</span>)</li>
                </ol>
                
                <p>Runtime complexity is primarily determined by API response time and the complexity of executed commands. No explicit empirical latency metrics were found in the codebase.</p>
                
                <h2>System Preparation & Licensing</h2>
                
                <h3>User-supplied Assets</h3>
                <ul>
                    <li>OpenAI API key (required, <span class="code-evidence">README.md:64-68</span>)</li>
                    <li>Natural language prompts</li>
                    <li>Optional image files for multimodal inputs (<span class="code-evidence">cli.tsx:58</span>)</li>
                    <li>Project files (code repository)</li>
                </ul>
                
                <h3>Repo-bundled Assets</h3>
                <ul>
                    <li>No large model weights or checkpoints (>1GB) are bundled</li>
                    <li>Configuration templates and examples</li>
                    <li>Documentation and examples</li>
                </ul>
                
                <h3>Licensing</h3>
                <ul>
                    <li>Code is licensed under Apache License 2.0 (<span class="code-evidence">LICENSE</span>)</li>
                    <li>Requires OpenAI API access, which has its own terms of service</li>
                    <li>No copyleft clauses identified; permissive license allows commercial use with attribution</li>
                </ul>
                
                <h2>Architecture Breakdown</h2>
                
                <div class="two-column">
                    <div class="column">
                        <div class="tech-card">
                            <h4>Classic Backend (≈90 LoC, key deps: meow, fs)</h4>
                            <ul>
                                <li>Command-line argument parsing via meow (<span class="code-evidence">cli.tsx:49-172</span>)</li>
                                <li>Configuration management (<span class="code-evidence">utils/config.ts</span>, 14.3KB)</li>
                                <li>File system operations for reading/writing code</li>
                            </ul>
                        </div>
                    </div>
                    <div class="column">
                        <div class="tech-card">
                            <h4>LLM Components (≈50 LoC, key deps: openai)</h4>
                            <ul>
                                <li>OpenAI API client integration (<span class="code-evidence">agent/agent-loop.ts</span>, 46.5KB)</li>
                                <li>Model selection and configuration (<span class="code-evidence">utils/model-utils.ts</span>, 2.5KB)</li>
                                <li>Token usage tracking (<span class="code-evidence">utils/approximate-tokens-used.ts</span>, 1.6KB)</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="two-column">
                    <div class="column">
                        <div class="tech-card">
                            <h4>Promptware (≈30 LoC, key deps: marked, js-yaml)</h4>
                            <ul>
                                <li>Instruction loading from multiple sources (<span class="code-evidence">README.md:185-191</span>)</li>
                                <li>Project documentation merging</li>
                                <li>Markdown parsing for instructions (<span class="code-evidence">package.json:45-46</span>)</li>
                            </ul>
                        </div>
                    </div>
                    <div class="column">
                        <div class="tech-card">
                            <h4>Unique Components (≈150 LoC, key deps: none)</h4>
                            <ul>
                                <li>Platform-specific sandboxing (<span class="code-evidence">utils/agent/sandbox/macos-seatbelt.ts</span>, 4.3KB)</li>
                                <li>Patch application system (<span class="code-evidence">agent/apply-patch.ts</span>, 18.6KB)</li>
                                <li>Command execution with security controls (<span class="code-evidence">agent/handle-exec-command.ts</span>, 11KB)</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <h2>Code Snippets Discussion</h2>
                
                <h3>Good Design Example 1: Progressive Permission Model</h3>
                
                <pre><code>// From approvals.ts - A well-designed permission system that balances security and convenience

// The policy types provide clear, graduated levels of automation
export type ApprovalPolicy =
  /**
   * Require user approval for all commands.
   */
  | "ask-for-all"
  /**
   * Auto-approve safe commands, ask for approval for unsafe commands.
   */
  | "auto-safe"
  /**
   * Auto-approve all commands, including potentially unsafe ones.
   * This is not recommended for production use.
   */
  | "auto-all";

// The safety assessment provides detailed reasoning for security decisions
export type SafetyAssessment =
  | {
      type: "auto-approve";
      reason: string;
    }
  | {
      type: "ask-user";
      reason?: string;
    };

// 4. Progressive disclosure of complexity
export function canAutoApprove(
  command: ReadonlyArray<string>,
  policy: ApprovalPolicy,
  writableRoots: ReadonlyArray<string>,
  env: NodeJS.ProcessEnv = process.env,
): SafetyAssessment {
  // Special case handling for patch commands
  if (command[0] === "apply_patch") {
    return command.length === 2 && typeof command[1] === "string"
      ? canAutoApproveApplyPatch(command[1], writableRoots, policy)
      : {
          type: "ask-user",
          reason: "Invalid apply_patch command format",
        };
  }

  // Policy-based decision making
  if (policy === "ask-for-all") {
    return { type: "ask-user" };
  } else if (policy === "auto-all") {
    return {
      type: "auto-approve",
      reason: "Auto-approving all commands as per policy",
    };
  }

  // For auto-safe policy, check if command is in the allowlist
  const isAllowlisted = ALLOWLISTED_COMMANDS.some((allowlisted) => {
    return commandMatchesAllowlisted(command, allowlisted, env);
  });

  return isAllowlisted
    ? {
        type: "auto-approve",
        reason: "Command is in the allowlist of safe commands",
      }
    : { type: "ask-user" };
}</code></pre>
                
                <p>This code exemplifies excellent design through its:</p>
                
                <ol>
                    <li><strong>Clear Type Definitions</strong> - Using TypeScript's discriminated unions for type safety</li>
                    <li><strong>Progressive Security Model</strong> - Providing multiple levels of automation while maintaining safety</li>
                    <li><strong>Separation of Concerns</strong> - Breaking complex logic into smaller, focused functions</li>
                    <li><strong>Defensive Programming</strong> - Careful validation of inputs before processing</li>
                    <li><strong>Self-documenting Code</strong> - Comprehensive comments explaining the security implications</li>
                </ol>
                
                <h3>Design Example 2 (With Concerns): Platform-Specific Sandboxing</h3>
                <p><code>codex/codex-cli/src/utils/agent/handle-exec-command.ts</code></p>
                
                <pre><code>async function getSandbox(runInSandbox: boolean): Promise<SandboxType> {
  if (runInSandbox) {
    if (process.platform === "darwin") {
      return SandboxType.MACOS_SEATBELT;
    } else if (await isInLinux()) {
      return SandboxType.NONE;
    } else if (process.platform === "win32") {
      // On Windows, we don't have a sandbox implementation yet, so we fall back to NONE
      // instead of throwing an error, which would crash the application
      log(
        "WARNING: Sandbox was requested but is not available on Windows. Continuing without sandbox.",
      );
      return SandboxType.NONE;
    }
    // For other platforms, still throw an error as before
    throw new Error("Sandbox was mandated, but no sandbox is available!");
  } else {
    return SandboxType.NONE;
  }
}</code></pre>
                
                <p>This code reveals an interesting design choice in the sandboxing architecture:</p>
                
                <ol>
                    <li><strong>Incomplete Cross-Platform Support</strong> - Despite defining <code>LINUX_LANDLOCK</code> in the interface enum, only macOS has an actual sandbox implementation (Seatbelt). Linux and Windows both fall back to <code>NONE</code>.</li>
                    <li><strong>Graceful Degradation</strong> - The system provides a clear warning on Windows rather than failing completely, showing a pragmatic approach to platform limitations.</li>
                    <li><strong>Fail-Closed Security</strong> - For unknown platforms, the system fails closed (throws an error) rather than proceeding without security, following the principle of secure defaults.</li>
                    <li><strong>Forward-Looking Design</strong> - The interface defines sandbox types that aren't yet implemented, suggesting the developers planned for future expansion but prioritized shipping a working solution for macOS first.</li>
                    <li><strong>Use Docker as a Sandbox</strong> - In README.md, it is mentioned that <code>- **Linux** – there is no sandboxing by default.
  We recommend using Docker for sandboxing, where Codex launches itself inside a **minimal
  container image** and mounts your repo _read/write_ at the same path. A
  custom `iptables`/`ipset` firewall script denies all egress except the
  OpenAI API. This gives you deterministic, reproducible runs without needing
  root on the host. You can use the [`run_in_container.sh`](./codex-cli/scripts/run_in_container.sh) script to set up the sandbox.</code></li>
                </ol>
                
                <h3>Design Example 3: User Input to LLM Workflow</h3>
                <p><code>src/utils/agent/agent-loop.ts</code> and related files</p>
                
                <pre><code>// From agent-loop.ts - How user input flows through the system to the LLM and back

async run(
  input: Array&lt;ResponseInputItem&gt;,  // User's prompt, converted to OpenAI format
  previousResponseId: string = "",
): Promise&lt;void&gt; {
  try {
    // Create the OpenAI API request with appropriate system instructions
    const response = await this.oai.chat.completions.create({
      model: this.model,
      messages: [
        {
          role: "system",
          content: this.instructions || DEFAULT_SYSTEM_PROMPT,
        },
        // Previous messages and user input
        ...input,
      ],
      tools: [
        // Tool definitions for executing commands, editing files, etc.
        // ...
      ],
      stream: true,  // Enable streaming for responsive UI
    });

    // Process the streaming response
    for await (const chunk of response) {
      // Handle different types of response chunks (text, tool calls)
      // and emit them to the UI
      // ...
    }
  } catch (error) {
    // Error handling
  }
}</code></pre>
                
                <p>This code demonstrates several important design patterns:</p>
                
                <ol>
                    <li><strong>Streaming Architecture</strong> - Uses OpenAI's streaming API to provide real-time responses to users</li>
                    <li><strong>Separation of Concerns</strong> - Cleanly separates input processing, LLM interaction, and output handling</li>
                    <li><strong>Tool-based Approach</strong> - Structures AI capabilities as discrete tools that can be individually approved</li>
                    <li><strong>Error Resilience</strong> - Includes robust error handling for API issues</li>
                    <li><strong>Stateful Conversation</strong> - Maintains conversation context across multiple interactions</li>
                </ol>
                
                <h2>Limitations & Risks</h2>
                
                <div class="tech-card impact-high">
                    <h4>High Impact</h4>
                    <ul>
                        <li><strong>Limited Sandboxing on Linux</strong> - Less robust security on Linux compared to macOS (<span class="code-evidence">README.md:148-153</span>)</li>
                        <li><strong>Zero Data Retention Limitation</strong> - Incompatible with organizations using ZDR policy (<span class="code-evidence">README.md:342-361</span>). OpenAI's API retains data for model improvement, creating a barrier for regulated industries (finance, healthcare, government) with strict data privacy requirements.</li>
                    </ul>
                </div>
                
                <div class="tech-card impact-medium">
                    <h4>Medium Impact</h4>
                    <ul>
                        <li><strong>Limited Platform Support</strong> - No direct Windows support, requires WSL2 (<span class="code-evidence">README.md:333-338</span>)</li>
                        <li><strong>Node.js Version Requirement</strong> - Requires Node.js 22+, potentially limiting adoption in environments with older Node versions (<span class="code-evidence">package.json:29</span>)</li>
                    </ul>
                </div>
                
                <div class="tech-card impact-low">
                    <h4>Low Impact</h4>
                    <ul>
                        <li><strong>Experimental Status</strong> - Project labeled as experimental and under active development (<span class="code-evidence">README.md:45-54</span>)</li>
                        <li><strong>API Dependency</strong> - Requires OpenAI API key and costs; service disruptions would render tool unusable (<span class="code-evidence">README.md:64-68</span>)</li>
                    </ul>
                </div>
                
                <h2>Competitive Context</h2>
                
                <p>Compared to GitHub Copilot CLI, Codex provides more granular control over execution permissions and focuses on terminal-based workflows rather than IDE integration. Codex's sandboxing approach (<span class="code-evidence">utils/agent/sandbox</span>) is more comprehensive, while Copilot CLI typically relies on IDE security boundaries.</p>
                
                <h2>Recommendations</h2>
                
                <ol>
                    <li><strong>Implement Cross-Platform Sandboxing</strong> - Develop a native Windows sandboxing solution to expand platform support beyond WSL2 requirement.</li>
                    <li><strong>Add Usage Monitoring Dashboard</strong> - Create a usage tracking system to help organizations monitor API costs and set budgets.</li>
                    <li><strong>Develop ZDR-Compatible Mode</strong> - Work with OpenAI to create a mode compatible with Zero Data Retention organizations to expand enterprise adoption.</li>
                    <li><strong>Create Enterprise Deployment Guide</strong> - Develop documentation for secure enterprise deployment, including best practices for API key management and usage policies.</li>
                </ol>
            </div>
        </div>
    </div>
    
    <section class="cta-section">
        <div class="container">
            <h2>Explore Codex CLI</h2>
            <p>The project is Apache 2.0 licensed and available on GitHub. If you're a developer who prefers terminal-based workflows, it's worth exploring how Codex CLI can enhance your productivity.</p>
            <a href="https://github.com/openai/codex-cli" class="cta-button">View on GitHub</a>
        </div>
    </section>
    
    <footer>
        <div class="container">
            <div class="social-links">
                <a href="#">#AI</a>
                <a href="#">#CLI</a>
                <a href="#">#OpenSource</a>
                <a href="#">#DevTools</a>
                <a href="#">#AIAssistant</a>
            </div>
            <p>© 2025 OSS Study</p>
        </div>
    </footer>
</body>
</html>
